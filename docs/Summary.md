“Neutron transport is  the study of the motions and interactions of neutrons with materials.” Nuclear engineers need to study the motion of neutrons, including their speed and direction, to deal with problems related to nuclear reactor cores. Scientists often use computers to simulate neutron transport, and Monte Carlo method is one of the most commonly used methods.
There are many ways to reduce the error of Monte Carlo method. Variance reduction is a “procedure used to increase the precision of the estimates that can be obtained for a given number of iterations”. 
In the paper “An easy to implement global variance reduction procedure for MCNP”, the author introduces the global variance reduction (GVR) method, which could be applied to any Monte Carlo particle transport code that allows a mesh-based application of weight windows.
The procedure includes:
1.	Preprocess the data of weight window. This step aims to form a file (wwout) with certain header and column. Could be skipped.
2.	The second step is an analog run that serves to provide a file containing flux and relative error information of the mesh tally.
3.	The third and final step starts by reading in the data from the mctal/meshtal and wwout files. The flux or relative error information is converted into weight window boundaries and written to the appropriate position in the wwout file. A final run of MCNP is then performed with the modified wwout file as weight window input.

In the paper **“Comparison of global variance reduction techniques for Monte Carlo radiation transport simulations of ITER”**, the author compares the methods for global variance reduction techniques. He concludes that the most effective method is Method of Automatic Generation of Importance by Calculation. (MAGIC)

1.	Set up a flux mesh tally corresponding to required mesh weight window, using energy bins if required. Run MCNP in analogue mode. Use multi-group cross-section data and high energy cut-off (optional). Chosen energy cut-off should correspond to a mean free path no greater than the mesh voxel size.
2.	Read and process the resulting mesh tally data. Normalize the flux to 0.5 in the source region, and reorder the flux data to correspond with MCNP weight window file format. Create weight window file with appropriate header information.
3.	Modify MCNP input file to use external weight window file. Run the MCNP model again.
4.	Examine the result. If neutrons have not penetrated through the model, further iterations are required. In this case, using the new mesh tally result, repeat step 2 to obtain a weight window file.
5.	If an artificially high energy cut-off was specified, reduce it with each iteration as the particles propagate through the model. Once an acceptable particle distribution solution has been obtained over the entire model, the final iteration should be performed with the appropriate energy cut-off and cross-sections.

In the paper **“Comparison of Hybrid Methods for Global Variance Reduction in Shielding Calculations”**, the author states that one way to enhance the Monte Carlo is developing the importance map. To create importance map, researchers could use forward estimates or forward and adjoint estimates, which can be implemented using MAVRIC.

**“Improving PWR core simulations by Monte Carlo uncertainty analysis and Bayesian inference”**
Two different approaches are currently used to propagate nuclear data uncertainties to integral observable uncertainties: perturbation theory and Monte Carlo sampling.
The PWR core analysis is generated by SEANAP system. Then the nuclear data random sampling will be used. It will provide Monte Carlo sampling of nuclear data which can be used in PWR core analysis, including average fission neutron multiplicities, resonance parameters, cross sections, angular distributions and decay data. Then researchers use MOCABA to apply Bayesian updating of predictions.

**“On-The-Fly Judgments of Monte Carlo Fission Source Convergence”**
Using the Monte Carlo method, the source distributions will finally converge to the fluctuation range of stationarity. Researchers take samples from different numbers of cycles. It shows that the step-refined source convergence diagnostics is potentially an effective on-the-fly judgement.

**“Reducing the Dimensionality of Data with Neural Networks”**
Researchers always try dimensionality reduction to facilitates the classification, visualization, communication and storage of high-dimensional data. PCA is a dimensionality reduction method that commonly used in practice.

**“Self-learning Monte Carlo method”**
Monte Carlo sampling uses large amount of samples to obtain the statistically exact value of a physical observation. To enhance the efficiency of Monte Carlo update, researchers develop the self-learning Monte Carlo method (SLMC). SLMC generates trial simulations by local updates, which serves as training data, then applies machine learning algorithms. Next step is creating moves according to the learning result and determining whether the move is acceptable.  
